---
title: "Building a genetic linkage map of an autotetraploid population using MAPpoly"
author: "Marcelo Mollinari, Gabriel Gesteira, Guilherme Pereira, A Augusto Garcia, Zhao-Bang Zeng"
date: '`r Sys.Date()`'
output:
  rmdformats::downcute:
    toc_depth: 3
    lightbox: TRUE
    use_bookdown: TRUE
linestretch: 1.1
bibliography: biblio.bib
---

```{r setup, include = FALSE, eval = TRUE}
require(mappoly)
#load('all_run.RData')
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE, cache.lazy = FALSE)
knitr::opts_chunk$set(eval = TRUE)
```

# Introduction

Linkage maps are essential tools in several genetic studies such as quantitative trait loci (QTL) analysis, understanding chromosomal evolutionary processes, assessment of collinearity between genomes, and study of meiotic processes. The principle behind linkage map construction is detecting recombinant events between genomic positions and summarizing them into pairwise recombination fractions. In diploids, the assessment of such a phenomenon is relatively straightforward. After the homolog duplication, sister chromatids pair up exchanging segments. The presence of informative markers, e. g. single nucleotide polymorphisms (SNPs) enable estimating the recombination fraction between pairs of genomic positions by comparing the chromosome constitution of parents and offspring.

In polyploids (species with more than two sets of homolog chromosomes, or homologs), the construction of such maps is more challenging. While in diploids a biallelic marker is fully informative to distinguish between both alleles present in a pair of homologs, in polyploids they allow accounting for proportions of allelic dosages. The limited information imposed by this system makes the assessment of recombination events during the meiosis troublesome, specially as the ploidy level gets larger. To recover the multiallelic information present in polyploid species, we need to account for recombination frequencies, estimate phase configurations and reconstruct the haplotypes of both parents and individuals in the population. 

<!-- Building genetic linkage maps is one of the leading steps for genetic studies of any species of interest. Due to its high informativity, genetic maps provide knowledge about the physical distance between markers (independent of non-physical factors) and their linkage phases, and also allows studies about genotype-phenotype association (such as QTL mapping), study of the genetic architecture of important traits, study of evolutionary processes, helps to assemble reference genomes, and so on.

Methods to build genetic linkage maps are widespread for diploid and autotetraploid organisms. However, there is a lack of available methods for organisms with higher ploidy levels, such as sweetpotato (*Ipomoea batatas*, 6x), sugarcane (*Saccharum spp.*, 6-14x), many forage crops and other species.

Multipoint procedures, such as the Hidden Markov Chain Model (HMM), are great alternatives to estimate both linkage phases and recombination fractions between markers due to its high statistical power. Therefore, it explores information of the entire population and accounts for all possible genotype probabilities given the observed data for a linkage group. However, the dimension of these probabilities grows exponentially as ploidy increases, and for high ploidy species, procedures that avoid the need of big computational structures, such as dimensional reduction and two-point approaches, are necessary.

Building genetic linkage maps for polyploid organisms also involves estimation of their haplotypes, including both parents and progeny individuals. The haplotypes depend on recombination fractions and linkage phases, which can be estimated by both two-point and HMM approaches depending on the ploidy level. Besides genetic linkage studies, haplotypes can be very useful for QTL mapping, genomic prediction and genome wide association studies, as they allow recovering the multiallelic nature of polyploid genotypes, reduce the dimension of datasets and consequently reduce computational efforts needed to run the statistical models.

MAPpoly is an under development R package that allows building genetic linkage maps for autopolyploids with even ploidy levels. In its current version, MAPpoly can handle ploidy levels up to 8x when using the HMM approach, and up to 12x when using the two-point approach. All two-point-based functions can be run on standard computers, but we strongly recommend the use of high performance computers for HMM-based functions.-->

`MAPpoly` is an R package fully capable of building genetic linkage maps for biparental populations in polyploid species with ploidy level up to 8x. It was developed as part of the [Genomic Tools for Sweetpotato Improvement](https://sweetpotatogenomics.cals.ncsu.edu/) (GT4SP), funded by [Bill and Melinda Gates Foundation](https://www.gatesfoundation.org/). All of the statistical procedures used in the functions presented in this document are detailed in @Mollinari2019 and @Mollinari2020. The results obtained with `MAPpoly` can be readily used for QTL mapping with the [QTLpoly package](https://github.com/guilherme-pereira/QTLpoly), which implements the procedures proposed by @Pereira2020.

Some characteristics of `MAPpoly` (v 0.2.1)

- Can handle [multiple dataset types](#datasets)
- Can handle a large number of markers. See [this publication](https://doi.org/10.1534/g3.119.400620) for an example of ~30,000 SNPs in hexaploid sweetpotato.
- Incorporates genomic information
- Explores multipoint information (through Hidden Markov Model)
- Can reconstruct haplotypes for parents and all individuals in the population
- Recovers the multiallelic nature of polyploid genomes
- Detects occurrence, location and frequency of multivalent pairing during meiosis
- Robust enough to build genetic linkage maps with multiallelic markers (when available - see function [merge_maps](https://www.rdocumentation.org/packages/mappoly/versions/0.2.0/topics/merge_maps))

## `MAPpoly` installation

## From CRAN (stable version)

To install MAPpoly from the The Comprehensive R Archive Network (CRAN) use

```R
install.packages("mappoly")
```

## From GitHub (development version)

You can install the development version from Git Hub. Within R, you need to install `devtools`:

```R
install.packages("devtools")
```

If you are using Windows, you must install the the latest recommended version of [Rtools](https://cran.r-project.org/bin/windows/Rtools/).

To install MAPpoly from Git Hub use

```R
devtools::install_github("mmollina/mappoly", dependencies=TRUE)
```
# Loading datasets {#datasets}

In its current version, MAPpoly can handle the following types of datasets:
1. CSV files 
2. MAPpoly files
    - Dosage based
    - Probability based
3. [fitPoly](https://CRAN.R-project.org/package=fitPoly) files
4. VCF files

MAPpoly also is capable of importing objects generated by the following R packages 

1. [updog](https://CRAN.R-project.org/package=updog)
2. [polyRAD](https://CRAN.R-project.org/package=polyRAD)
3. [polymapR](https://CRAN.R-project.org/package=polymapR)
    - Datasets
    - Maps

Both CSV and `MAPpoly` datasets are sensible to formatting errors, such as additional spaces, commas and wrong encoding (non-UTF-8). If you have any trouble, please double check your files before submitting an issue. You can find detailed steps of all supported files in the following sections. Also, in large datasets, it is expected that a considerable proportion of markers will contain redundant information. Thus, all reading functions will set these redundant markers aside to be included in the final map. 

## Reading CSV files

The preparation of a CSV file for MAPpoly can be done in Microsoft Excel or any other spreadsheet software of your preference.  In this file, each line contains a marker and each column contains information about the marker. In its current version, `MAPpoly` can handle .csv files with allelic dosage data. 

The first line of the CSV file should contain headers for all columns. The first five columns should include the following information: marker name, dosage for both parents (one column for each), a sequence number (e.g. a chromosome number, if available) and a sequence position (e.g. the marker position within the chromosome, if available). In addition to these five headers, you should include the name of all individuals in the population. From the second line onwards, all columns should contain its values, including allelic dosages for all individuals. Missing or absent values should be represented by NA.

NOTE: If genomic information is not available, the 'sequence' and 'sequence position' columns should be filled with NA's.

Example:

```{r, data set_example, out.width='90%', fig.align='center', fig.cap='Figure 1: Example of CSV data set', echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/mmollina/MAPpoly_vignettes/master/vignette_tetraploid/image/csv.png")
```

You can read CSV files with the `read_geno_csv` function:

```{r load_csv_file}
## Download CSV file from GitHub
ft <- "https://raw.githubusercontent.com/mmollina/SCRI/main/data/B2721_dose.csv"
tempfl <- tempfile()
download.file(ft, destfile = tempfl)
## Reading CSV file
dat.dose.csv <- read_geno_csv(file.in  = tempfl, ploidy = 4)
unlink(tempfl)
```

In addition to the CSV file path, you must indicate the ploidy level using the `ploidy` argument. This function automatically excludes uninformative markers. It also performs chi-square tests for all markers, considering the expected segregation under Mendelian inheritance, random chromosome pairing and no double reduction. You can optionally use the `filter.non.conforming` logical argument (default = `TRUE`), which excludes non-expected genotypes under these assumptions. However, keep in mind that the linkage analysis functions in MAPpoly do not support double-reduction and this can cause software failures.

## Reading MAPpoly files

MAPpoly can also handle two dataset types that follow the same format: (1) a genotype-based file (with allelic dosages) and (2) probability-based file. Both are text files with the same header, but with different genotype table formats.

For both files, the header should contain: ploidy level, number of individuals (nind), number of markers (nmrk), marker names (mrknames), individual names (indnames), allele dosages for parent 1 (dosageP), allele dosages for parent 2 (dosageQ), sequence/chromosome information (seq), position of each marker (seqpos), number of phenotypic traits (nphen) and the phenotypic data (pheno) if available. The header should be organized according to this example:

```
ploidy 4
nind 3
nmrk 5
mrknames M1 M2 M3 M4 M5
indnames Ind1 Ind2 Ind3
dosageP 0 2 0 0 3
dosageQ 1 2 1 1 3
seq 1 1 2 2 3
seqpos 100 200 50 150 80
nphen 0
pheno-----------------------
geno------------------------
```

For more information about MAPpoly file format, please see `?read_geno` and `?read_geno_prob` documentation from `MAPpoly` package.

### Using `read_geno` {#read_geno}

The header should be followed by a table containing the genotypes (allele dosages) for each marker (rows) and for each individual (columns), as follows:

|          | Individual 1 | Individual 2 | Individual 3 |
|----------|:------------:|:------------:|:------------:|
| Marker 1 | 1            | 0            | 0            |
| Marker 2 | 3            | 0            | 2            |
| Marker 3 | 1            | 0            | 0            |
| Marker 4 | 1            | 0            | 0            |
| Marker 5 | 3            | 4            | 4            |

The final file should look like the example below:

```
ploidy 4
nind 3
nmrk 5
mrknames M1 M2 M3 M4 M5
indnames Ind1 Ind2 Ind3
dosageP 0 2 0 0 3
dosageQ 1 2 1 1 3
seq 1 1 2 2 3
seqpos 100 200 50 150 80
nphen 0
pheno-----------------------
geno------------------------
1 0 0
3 0 2
1 0 0
1 0 0
3 4 4
```

Then, use the `read_geno` function to read your file:

```{r load_dose_file}
## Download dataset from GitHub
fl = "https://raw.githubusercontent.com/mmollina/SCRI/main/data/B2721_mappoly_dose"
tempfl <- tempfile()
download.file(fl, destfile = tempfl)
## Reading 
dat.dose.mpl <- read_geno(file.in  = tempfl, elim.redundant = TRUE)
unlink(tempfl)
```

### Using `read_geno_prob`

Following the same header described before, `read_geno_prob` reads a table containing the probability distribution for each combination of marker $\times$ individual. Each line on this table represents the combination of one marker with one individual, and the respective probabilities. The first two columns represent the marker and the individual, respectively, and the remaining elements represent the probability associated with each one of the possible dosages

| Marker | Individual | $p(d=0)$ | $p(d=1)$ | $p(d=2)$ | $p(d=3)$ | $p(d=4)$ |
|--------|:----------:|:--------:|:--------:|:--------:|:--------:|:--------:|
| M1     | Ind1       | 0.5      | 0.5      | 0.0      | 0.0      | 0.0      |
| M2     | Ind1       | 0.0      | 1.0      | 0.0      | 0.0      | 0.0      |
| M3     | Ind1       | 0.3      | 0.7      | 0.0      | 0.0      | 0.0      |
| M4     | Ind1       | 0.5      | 0.5      | 0.0      | 0.0      | 0.0      |
| M5     | Ind1       | 0.0      | 0.0      | 0.0      | 0.9      | 0.1      |
| M1     | Ind2       | 1.0      | 0.0      | 0.0      | 0.0      | 0.0      |
| M2     | Ind2       | 0.2      | 0.5      | 0.3      | 0.0      | 0.0      |
| M3     | Ind2       | 0.9      | 0.1      | 0.0      | 0.0      | 0.0      |
| M4     | Ind2       | 0.9      | 0.1      | 0.0      | 0.0      | 0.0      |
| M5     | Ind2       | 0.0      | 0.0      | 0.0      | 0.2      | 0.8      |
| M1     | Ind3       | 0.2      | 0.8      | 0.0      | 0.0      | 0.0      |
| M2     | Ind3       | 0.4      | 0.6      | 0.0      | 0.0      | 0.0      |
| M3     | Ind3       | 1.0      | 0.0      | 0.0      | 0.0      | 0.0      |
| M4     | Ind3       | 0.0      | 0.1      | 0.9      | 0.0      | 0.0      |
| M5     | Ind3       | 0.1      | 0.9      | 0.0      | 0.0      | 0.0      |

Notice that each marker $\times$ individual combination have $ploidy + 1$ probabilities, i.e., from zero to ploidy level. Also, each line must sum to 1. The final file (header + table) should look like the following example:

```
ploidy 4
nind 3
nmrk 5
mrknames M1 M2 M3 M4 M5
indnames Ind1 Ind2 Ind3
dosageP 0 2 0 0 3
dosageQ 1 2 1 1 3
seq 1 1 2 2 3
seqpos 100 200 50 150 80
nphen 0
pheno-----------------------
geno------------------------
M1 Ind1 0.5 0.5 0.0 0.0 0.0
M2 Ind1 0.0 1.0 0.0 0.0 0.0
M3 Ind1 0.3 0.7 0.0 0.0 0.0
M4 Ind1 0.5 0.5 0.0 0.0 0.0
M5 Ind1 0.0 0.0 0.0 0.9 0.1
M1 Ind2 1.0 0.0 0.0 0.0 0.0
M2 Ind2 0.2 0.5 0.3 0.0 0.0
M3 Ind2 0.9 0.1 0.0 0.0 0.0
M4 Ind2 0.9 0.1 0.0 0.0 0.0
M5 Ind2 0.0 0.0 0.0 0.2 0.8
M1 Ind3 0.2 0.8 0.0 0.0 0.0
M2 Ind3 0.4 0.6 0.0 0.0 0.0
M3 Ind3 1.0 0.0 0.0 0.0 0.0
M4 Ind3 0.0 0.1 0.9 0.0 0.0
M5 Ind3 0.1 0.9 0.0 0.0 0.0
```

To read the dataset use 

```{r load_data_w_probs}
## Download dataset from GitHub
ft="https://raw.githubusercontent.com/mmollina/SCRI/main/data/B2721_mappoly_prob"
tempfl <- tempfile()
download.file(ft, destfile = tempfl)
## Reading
dat.prob.mpl <- read_geno_prob(file.in  = tempfl, prob.thres = 0.95, elim.redundant = TRUE)
unlink(tempfl)
```
**Important note:** as this type of file contains the probability distribution of all possible dosages and it will take longer to read. 

You can define the minimum probability value necessary to call a dosage using the `prob.thres` argument. If the higher probability for a marker and individual passes this threshold, then its associated dosage is used. However, if none of the probabilities reach this threshold, then its dosage is considered missing (NA). Function `read_geno_prob` also performs the same filtering described in [`read_geno`](#read_geno) 

## Reading VCF files {#read_vcf}

`MAPpoly` can also handle VCF files (>= V.4.0) generated by the most programs, such as TASSEL, GATK, and Stacks. As few of them can handle poliploidy and estimate genotypes in a satisfactory manner, you may use other tools specifically developed to estimate allele dosages. Briefly, these programs use the allele read counts (or intensity) for each marker $\times$ individual combination, and determines which is the most likely allele dosage. Examples are [SuperMASSA](http://statgen.esalq.usp.br/SuperMASSA/), [fitPoly](https://cran.r-project.org/web/packages/fitPoly/index.html), [ClusterCall](https://potatobreeding.cals.wisc.edu/wp-content/uploads/sites/161/2017/08/ClusterCall_Download.zip), [updog](https://cloud.r-project.org/web/packages/updog/index.html), and  [PolyRAD](https://cran.r-project.org/web/packages/polyRAD/vignettes/polyRADtutorial.html). After allele dosage estimation, your VCF file should contain values for the field GT similar to **1/1/1/0** (a triplex marker in an autotetraploid, for example) rather than **1/0**. Since `MAPpoly` uses dosages (or their probabilities) to build genetic maps, we strongly recommend using programs capable of estimating dosages before building the map. `fitPoly`, `PolyRAD`, and `updog` have direct integration with `MAPpoly`, as will be described in the next sections.

To demonstrate the `read_vcf` function, let us download an autohexaploid sweetpotato VCF file from the `MAPpoly's` vignettes repository on Github and read it:

```{r load_vcf_data}
## Download dataset from GitHub
ft <- "https://github.com/mmollina/MAPpoly_vignettes/raw/master/data/BT/sweetpotato_chr1.vcf.gz"
tempfl <- tempfile()
download.file(ft, destfile = tempfl)
## Reading
dat.dose.vcf <- read_vcf(file = tempfl, parent.1 = "PARENT1", parent.2 = "PARENT2", verbose = FALSE)
unlink(tempfl)
```

Besides the path to your VCF file, you should indicate `parent.1` and `parent.2` names. Parent names must be exactly the same strings as in the VCF file. The ploidy level will be automatically detected, but you may indicate it using the optional `ploidy` argument. With this argument, the function will check for possible errors in your dataset. For species with variable ploidy levels (i.e. sugarcane), please indicate the desired ploidy level using the `ploidy` argument; if absent, `MAPpoly` will use the smallest ploidy level detected. 

This function also has options to filter out undesired markers or data points, such as those with low depth or high proportion of missing data. You can define the following filter arguments: set `min.av.depth` to remove markers with average depth below the provided value (default = 0); set `min.gt.depth` to remove data points that present depth below the provided (default = 0); set `max.missing` to any value between 0 and 1 in order to remove markers that present missing data proportion above this value (default = 1). `read_vcf` also perform the same filtering described for function [`read_geno`](#read_geno). Object generated by `read_vcf` has some additional information when compared to previous functions: reference and alternative alleles (bases) for each marker; and average depth of each marker. You can inspect all marker depths using the following code as an example:

```{r inspect_depth}
library(ggplot2)
dosage_combs = cbind(dat.dose.vcf$dosage.p, dat.dose.vcf$dosage.q)
dc_simplex = apply(dosage_combs,1,function(x) if(all(c(0,1) %in% x) | 
                                                 all(c(dat.dose.vcf$m-1, dat.dose.vcf$m) %in% x)) return(TRUE) else return(FALSE))
dc_dsimplex = apply(dosage_combs,1,function(x) if(all(x == c(1,1)) | 
                                                  all(x == c(dat.dose.vcf$m-1, dat.dose.vcf$m-1))) return(TRUE) else return(FALSE))

dc_simplex[which(dc_simplex == TRUE)] = "simplex"
dc_simplex[which(dc_dsimplex == TRUE)] = 'double simplex'
dc_simplex[which(dc_simplex == 'FALSE')] = 'multiplex'

data_depths = data.frame('Marker depths' = dat.dose.vcf$all.mrk.depth,
                         'Depth classes' = findInterval(dat.dose.vcf$all.mrk.depth, c(200,300,400,500,600,50000)),
                         'Dosage combinations' = dc_simplex, check.names = F)

ggplot(data_depths, aes(fill=`Dosage combinations`, x=`Depth classes`, y=`Marker depths`)) +
  geom_bar(position = 'stack', stat = 'identity') +
  scale_x_continuous(breaks=0:5, labels=c("[0,200)","[200,300)","[300,400)","[400,500)","[500,600)", "> 600"))
```

## Importing data from `fitPoly`

You can export datasets generated by `fitPoly` package using

```{r load_from_fitpoly}
## Downloading and reading B2721 fitPoly's probabilistic scores
address <- "https://github.com/mmollina/SCRI/raw/main/data/fitpoly_tetra_call/B2721_scores.zip"
tempfl <- tempfile(pattern = "B2721_", fileext = ".zip")
download.file(url = address, destfile = tempfl)
unzip(tempfl, files = "B2721_scores.dat")
unlink(tempfl)
dat <- read_fitpoly(file.in = "B2721_scores.dat", 
                    ploidy = 4, 
                    parent1 = "Atlantic", 
                    parent2 = "B1829", 
                    verbose = TRUE)
```

The input file should be generated using the function [`fitPoly::saveMarkerModels`](https://www.rdocumentation.org/packages/fitPoly/versions/3.0.0/topics/saveMarkerModels). [Here](https://github.com/mmollina/SCRI/blob/main/data/fitpoly_tetra_call/B2721_fitpoly_call.R) is an example of genotype calling using `saveMarkerModels`. If available, you can also include genome information in the dataset. [Here](https://github.com/mmollina/SCRI/blob/main/MAPpoly/get_solcap_snp_pos.R) is an example of including the _Solanum tuberosum_ genome v4.03 information.

```{r, adding_genome_info, echo=FALSE, results=FALSE}
source("https://raw.githubusercontent.com/mmollina/SCRI/main/MAPpoly/get_solcap_snp_pos.R")
```

## Importing data from `PolyRAD`

The R package `PolyRAD` has its own function to export genotypes to the `MAPpoly`'s genotype probability distribution format. One may use the commands above to import from `PolyRAD`:

```{r load_from_polyrad}
# load example dataset from polyRAD
library(polyRAD)
data(exampleRAD_mapping)
exampleRAD_mapping = SetDonorParent(exampleRAD_mapping, "parent1")
exampleRAD_mapping = SetRecurrentParent(exampleRAD_mapping, "parent2")
exampleRAD_mapping = PipelineMapping2Parents(exampleRAD_mapping)

# export to MAPpoly
outfile2 = tempfile()
Export_MAPpoly(exampleRAD_mapping, file = outfile2)

# Read in MAPpoly
mydata_polyrad = read_geno_prob(outfile2)
```

``` r
mydata_polyrad
```

## Importing data from `updog`

You can use `MAPpoly`'s function `import_from_updog` to import any dataset generated by `updog`'s function `multidog`, following the example below:

```{r load_updog_data, results=FALSE}
# Load example dataset from updog
library(updog)
data(uitdewilligen)
mout = multidog(refmat = t(uitdewilligen$refmat), 
                sizemat = t(uitdewilligen$sizemat), 
                ploidy = uitdewilligen$ploidy, 
                model = "f1",
                p1_id = colnames(t(uitdewilligen$sizemat))[1],
                p2_id = colnames(t(uitdewilligen$sizemat))[2],
                nc = 4)
mydata_updog = import_from_updog(mout)
```

Notice that `updog` removes both sequence and sequence position information that may be present in the VCF file. We highly recommend the incorporation of this information during the linkage map building, when available.

## Importing data from `polymapR`
Besides genotype calling packages, `MAPpoly` also is capable to import datasets and **phased** maps from `polymapR`. This functionality can be important when the user already have their map constructed using `polymapR` and wanted to obtain the genotype conditional probabilities using the HMM-based approach to be used in further analysis, e.g., QTL mapping, haplotype reconstruction, meiotic studies, etc. To import the dataset, use the following code

```{r import_polymapR_data, results=FALSE, fig.show = 'hide'}
require(polymapR)
data("screened_data3")
mappoly.data <- import_data_from_polymapR(screened_data3, ploidy = 4)
plot(mappoly.data)
```

Now, let us import the phased map used as example in polymapR

```{r, import_polymapR_map}
data("integrated.maplist", "marker_assignments_P1","marker_assignments_P2")
maplist <- create_phased_maplist(maplist = integrated.maplist,
                                 dosage_matrix.conv = screened_data3,
                                 marker_assignment.1=marker_assignments_P1,
                                 marker_assignment.2=marker_assignments_P2,
                                 ploidy = 4, verbose = FALSE)
 mappoly.maplist <- import_phased_maplist_from_polymapR(maplist, mappoly.data)
 plot_map_list(mappoly.maplist, col = "ggstyle")
 ## plot a segment of phased map (from 0 to 20 cM)
 plot(mappoly.maplist[[1]], mrk.names = TRUE, left.lim = 0, right.lim = 20, cex = .7)
```

## Combining multiple datasets

It is not rare to have multiple datasets from the same population or individuals from different sources of molecular data, such as SNP chips, GBS and/or microsatellites. `MAPpoly` can combine datasets for the same set of individuals using the function `merge_datasets`. To demonstrate its functionality, let us download two VCF files (autohexaploid sweetpotato) from the MAPpoly vignettes repository on Github, and read them using `read_vcf` function:

```{r merge_data, results=FALSE}
# Downloading VCF files regarding chromosome 1 and 2
download.file("https://github.com/mmollina/MAPpoly_vignettes/raw/master/data/BT/sweetpotato_chr1.vcf.gz", destfile = 'chr1.vcf.gz')
download.file("https://github.com/mmollina/MAPpoly_vignettes/raw/master/data/BT/sweetpotato_chr2.vcf.gz", destfile = 'chr2.vcf.gz')
data1 = read_vcf(file = 'chr1.vcf.gz', parent.1 = "PARENT1", parent.2 = "PARENT2", verbose = FALSE)
data2 = read_vcf(file = 'chr2.vcf.gz', parent.1 = "PARENT1", parent.2 = "PARENT2", verbose = FALSE)
```

As we can see, both have different markers for the same population:

```{r merge_data_2, results=FALSE}
# See datasets
print(data1)
print(data2)
```

Now, let us merge them 

```{r merge_data_3, results=FALSE}
# Merge datasets
merged_data = merge_datasets(data1, data2)
print(merged_data, detailed = TRUE)
```

# Exploratory Analysis 

For the purpose of this tutorial, we will keep using the tetraploid potato array data (loaded using the examples above). We will construct a genetic map of the B2721 population, which is a cross between two tetraploid potato varieties: Atlantic and B1829-5. The population comprises 160 offsprings genotyped with the SolCAP Infinium 8303 potato array. The dataset also contains the genomic order of the SNPs from the _Solanum tuberosum_ genome version 4.03. The genotype calling was performed with fitPoly R package using [this pipeline](https://github.com/mmollina/SCRI/blob/main/data/fitpoly_tetra_call/B2721_fitpoly_call.R). Another option would be to use ClusterCall and [this pipeline](https://mmollina.github.io/tutorials/solcap/solcap_example.html).

Once the data is loaded, you can explore the dataset using the `print` function:

```{r print_data_dose}
print(dat, detailed = TRUE)
```

This function shows information about the dataset including the ploidy level, total number of individuals, total number of markers, number of informative markers, proportion of missing data and redundant markers. If `detailed = TRUE`, the function also outputs the number of markers in each sequence (chromosome, in this case), if available, and the number of markers for dosage combinations between both parents.

You can also explore the dataset visually using the `plot` function:

```{r plot_data_dose}
plot(dat)
```
The output figure shows a bar plot on the left-hand side with the number of markers in each allele dosage combination between both parents. The right labels indicate allele dosages for Parent 1 and Parent 2, respectively. The upper-right plot contains the $\log_{10}(p-value)$ from $\chi^2$ tests for all markers, considering the expected segregation patterns under Mendelian inheritance. The lower-right plot contains a graphical representation of the allele dosages and missing data distribution for all markers and individuals. Finally, the bottom-right graphic shows the proportion of redundant markers in the dataset.

If you want to view a specific marker information, use the `plot_mrk_info` function. You need to indicate your dataset object using the `input.data` argument, and the desired marker using the `mrk` argument. You can indicate the marker using its number or its name (string):

```{r mrk_info1, fig.width=5}
plot_mrk_info(input.data = dat, mrk = 1979)
# or
# plot_mrk_info(input.data = dat, mrk = 'solcap_snp_c2_17752')
```

When applied to a dosage-based dataset, the function shows a figure with the marker name and position in the dataset, allele dosage in parents 1 and 2, proportion of missing data, p-value of the associated $\chi^2$ test, sequence and position information (when available). The figure also contains a plot with the allele dosage and missing data distribution in the population. When applied to a probability-based dataset, the function outputs the probability threshold and 3D scatter of the probability distribution for each individual. You can also print the absolute frequency of genotypes using

```{r, print_mrk}
print_mrk(dat, mrks = 'solcap_snp_c2_17752')
```

# Filtering and Quality Control
## Missing data filtering

The function `filter_missing` filters out markers and/or individuals that exceeds a defined threshold of missing data. The argument `input.data` should contain your dataset object, and you can choose to filter either by 'marker' or 'individual' using the `type` argument (string). You can also define the maximum proportion of missing data using the `filter.thres` argument (ranges from 0 to 1, i.e. a threshold of 0.05 will keep just markers or individuals with less than 5% of missing data). When `TRUE` (default), the `inter` argument plots markers or individuals vs. frequency of missing data.

```{r filter_missing}
# Filtering dataset by marker
dat <- filter_missing(input.data = dat, type = "marker", 
                               filter.thres = 0.05, inter = TRUE)
```

```{r}
# Filtering dataset by individual
dat <- filter_missing(input.data = dat, type = "individual", 
                               filter.thres = 0.025, inter = TRUE)                            
```

```{r}
print(dat)
```

In this dataset, 1230 markers had a proportion of missing data above the defined threshold (0.05), while 12 individuals exceeded the defined threshold. Then we will use the final filtered dataset during the rest of the analysis. Notice that the function `read_vcf` also provides parameters to filter out markers depending on their average depth and missing data, as well as removes data points that do not reach a minimum pre-defined depth value. Check the [`read_vcf`](#read_vcf) section for more information.

## Segregation test

Another important point to be considered is the expected marker segregation pattern under Mendelian inheritance. Here we will use the chi-square ($\chi^2$) to assess the segregation ditortion. The test matches expected genotype frequencies against observed frequencies and calculates the associated p-value. In order to define the p-value threshold for the tests, we will use the Bonferroni correction, which a good aproximation is obtained using 

$$\alpha_{thres} = \frac{\alpha}{\#markers}$$

We will also assume that only random chromosome bivalent pairing occurs and there is no double reduction.

```{r, echo=FALSE, results=FALSE}
source("https://raw.githubusercontent.com/mmollina/SCRI/main/MAPpoly/get_solcap_snp_pos.R")
```
```{r chisq_test}
pval.bonf <- 0.05/dat$n.mrk
mrks.chi.filt <- filter_segregation(dat, chisq.pval.thres =  pval.bonf, inter = TRUE)
seq.init <- make_seq_mappoly(mrks.chi.filt)
```

Notice that `filter_segregation` does not produce a filtered dataset; it just tells you which markers follow the expected Mendelian segregation pattern. To select these markers from your dataset, you may use `make_seq_mappoly` function

```{r plot_filt_seq, fig.width=7}
plot(seq.init)
```

All redundant markers identified during data reading step are stored in the main dataset. The redundant markers are automatically removed and can be added back once the maps are finished using the function `update_map` (described in details later in this tutorial).

# Two-point analysis{#tpt}

Once the markers are selected, we need to compute the pairwise recombination fraction between all of them (two-point analysis). The function `est_pairwise_rf` is used to estimate all the pairwise recombination fractions between markers in the sequence provided. Since the output object is too big to be fully displayed on the screen, `MAPpoly` shows only a summary. Parallel computation is available and, if you want to use it, you need to define the available number of cores in your machine and also guarantee that you have sufficient RAM memory for that. Remember that it is always good to leave one core available for the system, and be aware that this step **will take a while** to compute if you have few cores available.

```{r two_pt}
# Defining number of cores
n.cores = parallel::detectCores() - 1
#(~ 9.9 minutes using 23 cores)
all.rf.pairwise <- est_pairwise_rf(input.seq = seq.init, ncpus = n.cores)
all.rf.pairwise
```

To assess the recombination fraction between a particular pair of markers, say markers 2204 and 4508, you can use the following

```{r, plot_twopt_example1}
all.rf.pairwise$pairwise$`2204-4508`
```
In this case, `2204-4508` represents the position of the markers in the filtered data set. The name of the rows have the form `x-y`, where `x` and `y` indicate how many homologous chromosomes share the same allelic variant in parents $P1$ and $P2$, respectively (see [this figure](https://www.g3journal.org/content/ggg/9/10/3297/F7.large.jpg) in @Mollinari2019 for notation). The first column indicates the LOD Score in relation to the most likely linkage phase configuration. The second column shows the estimated recombination fraction for each configuration, and the third indicates the LOD Score comparing the likelihood under no linkage ($r = 0.5$) with the estimated recombination fraction (evidence of linkage). These results can be plotted using

```{r, plot_twopt_example2, fig.width=5, fig.align="center"}
plot(all.rf.pairwise, first.mrk = 2204, second.mrk = 4508)
```
## Assembling recombination fraction and LOD Score matrices

Recombination fraction and LOD Score matrices are fundamental in genetic mapping. Later in this tutorial, we will use these matrices as the basic information to order markers and also to perform some diagnostics. To convert the two-point object into recombination fraction and LOD Score matrices, we need to assume thresholds for the three columns observed in the previous output. The arguments `thresh.LOD.ph` and `thresh.LOD.rf` set LOD Scores thresholds for the second most likely linkage phase configuration and recombination fraction. Here we assume `thresh.LOD.ph = 0` and `thresh.LOD.rf = 0`, thus no matter how likely is the second best option, the function will consider the most likely. The argument `thresh.rf = 0.5` indicates that the maximum accepted recombination fraction is `0.5`. To convert these values in a recombination fraction matrix, we use the function `rf_list_to_matrix`.

```{r rf_mat, echo=TRUE}
mat <- rf_list_to_matrix(input.twopt = all.rf.pairwise)
```

For big datasets, you may use the multi-core support to perform the conversions, using the parameter `ncpus` to define the number of CPU's. We can plot the recombination fraction matrix using `plot(mat)`, however, if the markers are not ordered, this command will yield a heat-map with no distinct pattern, which will have almost no use. Further, in this tutorial, we will show how to use the The UPGMA clustering algorithm to form linkage groups and the MDS algorithm to order markers within each group. For now, let us use the chromosomes and marker order from the reference genome using function`get_genomic_order`. If the reference order is consistent with the marker order in this specific population, we should observe a block-diagonal matrix and a monotonic pattern within each sub-matrix. Since the recombination fraction matrix dimensions for the whole genome are usually large, it is possible to summarize neighboring cells' information using a pre-defined grid. The size of the grid is determined by the aggregation factor `fact`. Using `fact = 5`, for instance, will average the recombination fractions of cells within a $5 \times 5$ grid producing the following heatmap

```{r plot_full_mat, fig.width=7, fig.height=7}
id<-get_genomic_order(seq.init)
s.o <- make_seq_mappoly(id)
plot(mat, ord = s.o$seq.mrk.names, fact = 5)
```

As expected, we observe the block-diagonal matrix with monotonic patterns. In the previous case, the thresholds allowed to plot almost all points in the recombination fraction matrix. The empty cells in the matrix (if any) indicate marker combinations where it is impossible to detect recombining events using two-point estimates (e.g., between $1 \times 0$ and $0 \times 1$ marker). Yet, if the thresholds become more stringent (higher LODs and lower rf), the matrix becomes more sparse.

# Assembling linkage groups

The function `group_mappoly` assign markers to linkage groups using the recombination fraction matrix obtained above. The user can provide an expected number of groups or run the interactive version of the function using `inter = TRUE`. Since in this data set we expect 12 linkage groups (basic chromosome number in potato), we use `expected.groups = 12`. If the data set provides the chromosome where the markers are located, the function allows comparing the groups obtained using the pairwise recombination fraction and the chromosome information provided using the `comp.mat = TRUE`.

```{r group}
grs <- group_mappoly(input.mat = mat,
                     expected.groups = 12,
                     comp.mat = TRUE, 
                     inter = TRUE)
grs
```

Here, we have the 4986 markers distributed in 12 linkage groups. The rows indicate linkage groups obtained using linkage information and the columns are the chromosomes in the reference genome. Notice the diagonal indicating the concordance between the two sources of information. Now, we can plot the resulting marker cluster analysis.

```{r plot_group, fig.width=10, fig.height=7}
plot(grs)
```

Once the linkage groups are properly assembled, we use the function `make_seq_mappoly` to make marker sequences from the group analysis. We will assemble a list with 12 positions, each one containing the corresponding linkage group sequence. Also, we will use only markers allocated in the diagonal of the previous comparison matrix. Thus only markers that were assigned to a particular linkage group using both sources of information will be considered. We will also assemble a smaller two-point object using the functions `make_pairs_mappoly` and `rf_snp_filter` to facilitate further parallelization procedures.

```{r make_lgs}
# genome correspondence
z <- as.numeric(colnames(grs$seq.vs.grouped.snp)[1:12])
LGS<-vector("list", 12)
for(j in 1:12){
    temp1 <- make_seq_mappoly(grs, j, genomic.info = 1)
    tpt <- make_pairs_mappoly(all.rf.pairwise, input.seq = temp1)
    temp2 <- rf_snp_filter(input.twopt = tpt, diagnostic.plot = FALSE)
    lgtemp <- get_genomic_order(temp2)
    LGS[[z[j]]] <- list(lg = make_seq_mappoly(lgtemp), tpt = tpt)
}
```

Now, let us print the recombination fraction matrices for each linkage group.

```{r, all_mat_rf, echo = FALSE, results='hide', fig.width=7, fig.height=7}
op <- par(mfrow = c(3, 4), pty = "s", mar=c(1,1,1,1))
for(i in 1:12)
  plot(rf_list_to_matrix(LGS[[i]]$tpt), ord = LGS[[i]]$lg$seq.mrk.names, 
       main.text = paste0("LG", i), index = FALSE, fact = 5)
par(op)
```

# Estimating the map for a given order

In this section, we will construct the genetic map for a single linkage group. Latter in this tutorial, we will use a parallelized version of the procedures presented in this section to build the linkage map for all 12 potato linkage groups. In the first part of this section, we will use the marker order provided by the _Solanum tuberosum_ genome version 4.03. In a second part we will use the MDS algorithm to obtain a *de-novo* order of the markers based on the recombination fraction matrix. When a reference genome is available, but not fully collinear with the mapping population, the user should consider using both sources of information, as presented in the [Supplemental Material](https://gsajournals.figshare.com/articles/Supplemental_Material_for_Mollinari_et_al_2020/10255844?file=18517505) of our sweetpotato map. 

The estimation of the genetic map for a given order involves the computation of recombination fraction between adjacent markers and finding the linkage phase configuration of those markers in both parents. The core function to perform these tasks in `MAPpoly` is `est_rf_hmm_sequential`. This function uses the pairwise [recombination fraction](#tpt) as the first source of information to sequentially position allelic variants in specific homologs. For situations where pairwise analysis has limited power, the algorithm relies on the likelihood obtained through a hidden Markov model (HMM) @Mollinari2019. Once all markers are positioned, the final map is reconstructed using the HMM multipoint algorithm. 

```{r, phase_example, out.width='90%', fig.align='center', fig.cap='Example of sequential phasing', echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/mmollina/SCRI/main/docs/phase.gif")
```

Several arguments are available to control the inclusion and phasing of the markers in the chain. The argument `start.set` defines the number of initial markers used in an exhaustive search for the most probable configuration. After that, markres are sequentially added to the end of the map. `thres.twopt` receives the threshold to whether when the linkage phases compared via two-point analysis should be considered, and the HMM analysis should not be used to infer the linkage phase (A. K. A. $\eta$ in @Mollinari2019). `thres.hmm` receives the threshold for keeping competing maps computed using HMM (if the two-point analysis was not enough) in the next round of marker insertion. `extend.tail` indicates the number of markers that should be considered at the end of the chain to compute the multilocus genetic map when inserting a new marker. `tol` and `tol.final` receive the desired accuracy to estimate the sub-maps during the sequential phasing procedure and the desired accuracy in the final map. `phase.number.limit` receives the limit number of linkage phase configurations to be tested using HMM. `info.tail` is a logical argument: if TRUE it uses the complete informative tail (last markers in the chain that allow all homologous to be distinguished in the parents) of the chain to calculate the likelihood of the linkage phases. 

First, as an example, let us estimate the map for linkage group 10. The values used for all arguments were obtained using a balance of processing speed and accuracy of the algorithm. As an exercise, it is interesting to try different values and check out the results. For now, let us stick with the following values (**this step can take some hours to finish**, depending on chosen parameters):

```{r, map_lg10, results=FALSE}
lg10.map <- est_rf_hmm_sequential(input.seq = LGS[[10]]$lg,
                                start.set = 10,
                                thres.twopt = 10, 
                                thres.hmm = 10,
                                extend.tail = 30,
                                info.tail = TRUE, 
                                twopt = LGS[[10]]$tpt,
                                sub.map.size.diff.limit = 10, 
                                phase.number.limit = 20,
                                reestimate.single.ph.configuration = TRUE,
                                tol = 10e-3,
                                tol.final = 10e-4)
```

Now, use the functions `print` and `plot` to view the results:

```{r map_lg10_plot, echo=TRUE, fig.width=10}
print(lg10.map)
plot(lg10.map)
```

Back rectangles indicate the presence of the allelic variant in each one of the four homologous in both parents. One also can print a detailed version of the map and plot a specific map segment using the following code.

```{r, eval=FALSE}
print(lg10.map, detailed = TRUE)
```
```{r, echo=TRUE, fig.width=7, fig.height=7}
plot(lg10.map, left.lim = 30, right.lim = 40, mrk.names = TRUE) 
```

## Reestimating the map considering genotyping errors

Though current technologies enabled the genotyping of thousands of SNPs, they are quite prone to genotyping errors, especially in polyploid species. One way to address this problem is to associate a probability distribution to each one of the markers and allow the HMM to update their probability. This procedure can be applied using either the probability distribution provided by the genotype calling software (loaded in `MAPpoly` using the function `read_geno_prob`) or assuming a global genotype error. For a detailed explanation of this procedure, please see @Mollinari2019. Briefly, the use of a prior information will update the genotype of the markers based on a global chromosome structure. One ca use ...

```{r, map_prior1_lg10}
lg10.map.prob <- est_full_hmm_with_prior_prob(input.map = lg10.map)
plot(lg10.map.prob)
```


```{r, map_prior_lg10}
lg10.map.err <- est_full_hmm_with_global_error(input.map = lg10.map, error = 0.05)
plot(lg10.map.err)
```

Notice that a global genotyping error of 5% was used, and the resulting map was smaller than the previous one. Also, some markers were "attracted" and some markers were "repealed" as a result of the smaller confidence used for each marker genotype.

## Reinserting redundant markers

As mentioned before, redundant markers are automatically removed during the analysis to reduce computational calculations. Besides that, one may want to see the genetic linkage maps considering all markers in the full dataset, including the redundant ones. The addition of redundant markers to a map can be done by just calling the function `update_map`. Here we will show the addition in the previous map:


```{r}
lg10.map.updated = update_map(lg10.map.err)
lg10.map.err
lg10.map.updated
```

As can be seen, both maps are identical except for the number of markers.


# Ordering markers using MDS and reestimating the map

So far the map was reestimated using the genomic order. In real situations, unless a genomic information is provided,  the markers need to be ordered using an optimization technique. Here, we use the MDS (multidimensional scaling) algorithm, proposed in the context of genetic mapping by @Preedy2016. The MDS algorithm requires a recombination fraction matrix, which will be transformed in distances using a mapping function (in this case the Haldane's mapping function). First, let us gather the pairwise recombination fractions for all three linkage groups:

```{r mat_for_ordering, results='hide', results=FALSE}
mt <- lapply(LGS, function(x) rf_list_to_matrix(x$tpt))
```

Now, for each matrix contained in the object `mt`, we use the MDS algorithm:

```{r mds, results='hide', results=FALSE}
mds.ord <- lapply(mt, mds_mappoly)
```

Usually at this point, the user can make use of diagnostic plots to remove markers that are disturbing the ordering procedure. Here we didn't use that procedure, but we encourage the user to check the example in `?mds_mappoly`. Now, let us compare the estimated and the genomic orders (feel free to run the last commented line and see interactive plots):

```{r compare_order}
LGS.mds<-vector("list", 12)
for(j in 1:12){
  lgtemp <- make_seq_mappoly(mds.ord[[j]])
  LGS.mds[[j]] <- list(lg = lgtemp, 
      tpt = make_pairs_mappoly(all.rf.pairwise, input.seq = lgtemp))
}
```

```{r, results='hide', fig.width=10}
geno.vs.mds <- NULL
for(i in 1:length(LGS.mds)){
  geno.vs.mds<-rbind(geno.vs.mds,
                     data.frame(mrk.names = LGS.mds[[i]]$lg$seq.mrk.names,
                                mds.pos = seq_along(LGS.mds[[i]]$lg$seq.mrk.names),
                                genomic.pos = order(LGS.mds[[i]]$lg$sequence.pos),
                                LG = paste0("LG_", i)))
}

require(ggplot2)
p<-ggplot(geno.vs.mds, aes(genomic.pos, mds.pos)) +
  geom_point(alpha = 1/5, aes(colour = LG)) +
  facet_wrap(~LG) +  xlab("Genome Order") + ylab("Map Order")
p
#plotly::ggplotly(p)
```

Although several local inconsistencies occurred, the global diagonal pattern indicates a consistent order for all linkage groups using both approaches. Now, let us build the genetic map of linkage group 3 using the MDS order (remember that **this can take a while to finish**):

```{r, map_lg10_mds, results=FALSE}
lg10.map.mds <- est_rf_hmm_sequential(input.seq = LGS.mds[[10]]$lg,
                                      start.set = 10,
                                      thres.twopt = 10, 
                                      thres.hmm = 10,
                                      extend.tail = 30,
                                      info.tail = TRUE, 
                                      twopt = LGS.mds[[10]]$tpt,
                                      sub.map.size.diff.limit = 10, 
                                      phase.number.limit = 20,
                                      reestimate.single.ph.configuration = TRUE,
                                      tol = 10e-3,
                                      tol.final = 10e-4)
```

And plot the map:

```{r plot_mds_map}
plot(lg10.map.mds)
```

It is also possible to compare the maps using both genomic-based and MDS-based orders with the function `plot_map_list`:

```{r lg10_map_mds_plot, results='hide', fig.width=10, fig.height=5}
plot_map_list(list(genome = lg10.map, mds = lg10.map.mds), col = c("#E69F00", "#56B4E9"), title = "")
```
The genomic-based map included the same number of markers but is smaller than the MDS-based map, which indicates a better result. To formally compare the maps, one needs to select the markers that are present in both maps. Interestingly enough, both procedures included the same markers in the final map; however, we provide the code to perform the comparison even if the maps share only a subset of markers:

```{r map_comp}
mrks.in.gen<-intersect(lg10.map$maps[[1]]$seq.num, lg10.map.mds$maps[[1]]$seq.num)
mrks.in.mds<-intersect(lg10.map.mds$maps[[1]]$seq.num, lg10.map$maps[[1]]$seq.num)
if(cor(mrks.in.gen, mrks.in.mds) < 0){
  mrks.in.mds <- rev(mrks.in.mds)
  lg10.map.mds <- rev_map(lg10.map.mds)
}
map.comp.3.gen<-get_submap(input.map = lg10.map, match(mrks.in.gen, lg10.map$maps[[1]]$seq.num), verbose = FALSE)
map.comp.3.mds<-get_submap(input.map = lg10.map.mds, match(mrks.in.mds, lg10.map.mds$maps[[1]]$seq.num), verbose = FALSE)
prob.3.gen<-extract_map(lg10.map)
prob.3.mds<-extract_map(lg10.map.mds)
names(prob.3.gen)<-map.comp.3.gen$maps[[1]]$seq.num
names(prob.3.mds)<-map.comp.3.mds$maps[[1]]$seq.num
```

```{r, results='hide', fig.align='center'}
matplot(t(data.frame(prob.3.gen,prob.3.mds[names(prob.3.gen)])), 
        type="b", pch="_", col=1, lty=1, lwd = .5, xlab= "", 
        ylab="Marker position (cM)", axes = F)
axis(2)
mtext(text = round(map.comp.3.gen$maps[[1]]$loglike,1), side = 1, adj = 0)
mtext(text = round(map.comp.3.mds$maps[[1]]$loglike,1), side = 1, adj = 1)
mtext(text = "Genomic", side = 3, adj = 0)
mtext(text = "MDS", side = 3, adj = 1)
```

Please notice that these maps have the same local inversions shown in the dot plots presented earlier. In this case, the log-likelihood of the genomic order is higher than the one obtained using the MDS order. For this linkage group, the genomic-based map was chosen as the best one.

# Parallel map construction
## Using one core by LG

Now, the mapping procedure will be applied to all linkage groups using parallelization. Although users must be encouraged to compare both MDS and genomic orders following the previous example, the genomic order will be considered as an example (remember that this step will take a **long time** to run):

```{r hmm_map, results=FALSE}
## ~13.3 min
## Performing parallel computation
my.phase.func<-function(X){
  x<-est_rf_hmm_sequential(input.seq = X$lg,
                                start.set = 10,
                                thres.twopt = 10, 
                                thres.hmm = 10,
                                extend.tail = 30,
                                info.tail = TRUE, 
                                twopt = X$tpt,
                                sub.map.size.diff.limit = 8, 
                                phase.number.limit = 10,
                                reestimate.single.ph.configuration = TRUE,
                                tol = 10e-3,
                                tol.final = 10e-4)
  return(x)
}
cl <- parallel::makeCluster(12)
parallel::clusterEvalQ(cl, require(mappoly))
parallel::clusterExport(cl, "dat")
MAPs <- parallel::parLapply(cl,LGS,my.phase.func)
parallel::stopCluster(cl)

```

A traditional linkage map plot can be generated including all linkage groups, using the function `plot_map_list`:

```{r print_maps, fig.width=10} 
plot_map_list(MAPs, col = "ggstyle")
```

Following the reconstruction of LG 3 shown before, let us consider a global genotyping error of 5% to reestimate the final maps:

```{r reestimate_map_with_error, results=FALSE}
my.error.func<-function(X){
  x<-est_full_hmm_with_global_error(input.map = X, 
                                    error = 0.05, 
                                    tol = 10e-4, 
                                    verbose = FALSE)
  return(x)
}
cl <- parallel::makeCluster(12)
parallel::clusterEvalQ(cl, require(mappoly))
parallel::clusterExport(cl, "dat")
MAP.err <- parallel::parLapply(cl,MAPs,my.error.func)
parallel::stopCluster(cl)
```

Comparing both results:

```{r final_plot, fig.width=10, fig.height=8}
all.MAPs <- NULL
for(i in 1:12) 
  all.MAPs<-c(all.MAPs, MAPs[i], MAP.err[i])
plot_map_list(map.list = all.MAPs, col = rep(c("#E69F00", "#56B4E9"), 12))
```

Then, the map that included modeling of genotype errors was chosen as the best one.

```{r print_err_maps, fig.width=10} 
plot_map_list(MAP.err, col = "ggstyle")
```

## Map vs. genome

````{r}
plot_genome_vs_map(MAP.err, same.ch.lg = TRUE)
````

## Map summary

After building two or more maps, one may want to compare summary statistics of those maps regarding the same chromosome, or even across chromosomes. A brief comparison can be done using the function `summary_maps`, which generates a table containing these statistics based on a list of `mappoly.map` objects:

```{r}
knitr::kable(summary_maps(MAPs))
```

## Export map 

```{r}
require(polymapR)
dat<-export_data_to_polymapR(hexafake)
F1checked <- checkF1(dosage_matrix = dat, 
                     parent1 = "P1",
                     parent2 = "P2",
                     F1 = colnames(dat)[-c(1:2)],
                     polysomic = TRUE, 
                     disomic = FALSE, 
                     mixed = FALSE, 
                     ploidy = 6)
 head(F1checked$checked_F1)
```

# Genotype conditional probabilities

In order to use the genetic map in [QTLpoly](https://github.com/guilherme-pereira/QTLpoly), one needs to obtain the conditional probability of all possible 36 genotypes along the 12 linkage groups for all individuals in the full-sib population. Let us use the function `calc_genoprob_error`, which similarly to `est_full_hmm_with_global_error` allows the inclusion of a global genotyping error:

```{r genoprob_2, results=FALSE}
genoprob.err <- vector("list", 12)
for(i in 1:12)
   genoprob.err[[i]] <- calc_genoprob_error(input.map = MAP.err[[i]], error = 0.05)
```

Here, a global genotyping error of 5% was used. Each position of any object in the list `genoprob.err` contains two elements: an array of dimensions $36 \times number \; of \; markers \times  number \; of \; individuals$ and the position of the markers in the maps in centimorgans.  Let us display the results for all linkage groups in individual 1:

```{r plot_genoprob_all, fig.width=10, fig.height=8}
ind <- 1
op <- par(mfrow = c(3, 4), pty = "s", mar=c(1,1,1,1)) 
for(i in 1:12)
{
  d <- genoprob.err[[i]]$map
  image(t(genoprob.err[[i]]$probs[,,ind]),
        col=RColorBrewer::brewer.pal(n=9 , name = "YlOrRd"),
        axes=FALSE,
        xlab = "Markers",
        ylab = "",
        main = paste("LG", i))
  axis(side = 1, at = d/max(d),
       labels =rep("", length(d)), las=2)
}
par(op)
```

In this figure, the x-axis represents the genetic map and the y-axis represents the 36 possible genotypes in the full-sib population. The color scale varies from dark purple (high probabilities) to light yellow (low probabilities). With the conditional probabilities computed, it is possible to use the object `genoprob.err` alongside with phenotypic data as the input of the software [QTLpoly](https://github.com/guilherme-pereira/QTLpoly), which is an under development software to map multiple QTLs in full-sib families of outcrossing autopolyploid species.

# Obtaining individual haplotypes

Once ready, the genotypic conditional probabilities can be used to recover any individual haplotype given the map (details described in @Mollinari2020). To generate this information, one may use the function `calc_homoprob` to account for the probabilities of each homologous, in all map positions for each individual. For example, let us view the homologous probabilities for chromosome 1 and individual 10:

```{r, haplotypes}
homoprobs = calc_homoprob(genoprob.err)
```

```{r}
plot(homoprobs, lg = 1, ind = 10)
```

Using this graphic, it is possible to identify regions of crossing-over occurrence, represented by the inversion of probability magnitudes between homologous from the same parent. It is also possible to view all chromosomes at the same time for any individual by setting the parameter `lg = "all"`. One may use this information to evaluate the quality of the map and repeat some processes with modifications, if necessary.

# Evaluating the meiotic process

MAPpoly also handles a function to evaluate the meiotic process that guided gamete formation on the studied population. Given genotype conditional probabilities, one may want to account for homologous pairing probabilities and detect the occurrence of preferential pairing, which is possible through the function `calc_prefpair_profiles`:

```{r, meiosis_evaluation}
prefpairs = calc_prefpair_profiles(genoprob.err)
```

The function returns an object of class `mappoly.prefpair.profiles`, which was saved as `prefpairs`. This object handles all information necessary to study pairing, such as the probability for each pairing configuration ($\psi$; see @Mollinari2019) inside each parent. For a more user-friendly visualization of the results, one may want to look at the `plot` output:

```{r, meiosis_evaluation_plot}
plot(prefpairs)
#save.image("all.analysis.rda")
```

This graphic shows information about all pairing configurations and their probabilities, the proportion of bivalent/multivalent pairing, and also the p-value for preferential pairing test for all markers inside each parent.


# References

